import os
import random
import argparse

import coolname
from aim.sdk.adapters.pytorch_lightning import AimLogger
from dotenv import load_dotenv

import torch
from torchvision.models import Inception3, GoogLeNet
import lightning.pytorch as pl

#https://ensemble-pytorch.readthedocs.io/en/latest/
from torchensemble import VotingClassifier, BaggingClassifier, GradientBoostingClassifier, FusionClassifier, SnapshotEnsembleClassifier, FastGeometricClassifier, AdversarialTrainingClassifier

if __name__ == '__main__':
    import sys, pathlib
    PROJECT_ROOT = pathlib.Path(__file__).parent.parent.absolute()
    if sys.path[0] != str(PROJECT_ROOT): sys.path.insert(0, str(PROJECT_ROOT))

from src.multiclass.models import check_model_name, MulticlassClassifier
from src.train import setup_model_and_datamodule
from src.multiclass.callbacks import BarPlotMetricAim, PlotPerclassDropdownAim, PlotConfusionMetricAim
from src.patches.aim_patches import AimLoggerWithContext

ENSEMBLE_CHOICES = (
    'Voting',
    'Bagging',
    'Boosting',
    'Fusion',
    'Snapshot',
    'FastGeometric',
    'Adversarial')


def argparse_init(parser=None):
    if parser is None:
        parser = argparse.ArgumentParser(description='Train, Run, and perform other tasks related to ifcb and general image classification!')

    # DATASET #
    dataset = parser.add_argument_group(title='Dataset', description=None)
    dataset.add_argument('--classlist', required=True, help='A text file, each line is a class label (the label order is significant), or a json dict')
    dataset.add_argument('--trainlist', required=True, help='A text file, one sample per line, with class-index and image path per line, or a json dict')
    dataset.add_argument('--vallist', required=True, help='Like trainlist, but for validation metrics and early-stopping/overfit-prevention')

    # TRAINING TRANSFORMS #
    dataset.add_argument('--flip', choices=['x', 'y', 'xy'],
                      help='Training images have 50%% chance of being flipped along the designated axis: (x) vertically, (y) horizontally, (xy) either/both. May optionally specify "+V" to include Validation dataset')

    # TRACKING #
    aimstack = parser.add_argument_group(title='AimLogger', description='Aimlogger repo and artifacts settings need to be set using --env ENVFILE')
    aimstack.add_argument('--run', help='The name of this run. A run name is automatically generated by default')
    aimstack.add_argument('--experiment', default='ENSEMBLE', help='The broader category/grouping this RUN belongs to')
    aimstack.add_argument('--note', help='Add any kind of note or description to the trained model. Make sure to use quotes "around your message."')
#    aimstack.add_argument('--repo', help='Aim repo path. Also see: Aim environment variables. Default is ".aim"')
#    aimstack.add_argument('--artifacts-location', default='.aim/artifacts', help='Aim Artifacts location. Also see: Aim environment variables. Default is ".aim/artifacts"')
    #aimstack.add_argument('--plot', nargs='+', action='append', ...)
    #aimstack.add_argument('--callback', nargs='+', action='append', ...)
    #aimstack.add_argument('--metric', nargs='+', action='append', ...)

    # ENSEMBLE
    ensemble = parser.add_argument_group(title='Model Parameters')
    ensemble.add_argument('--ensemble', metavar='METHOD', choices=ENSEMBLE_CHOICES, help='Ensemble Classifier Methods from torchensemble')
    ensemble.add_argument('--num-ensembles', type=int, default=4, help='number of ensembles')
    ensemble.add_argument('--voting-strategy', default='soft', choices=('soft','hard'), help='Only for "Voting" and "Snapshot" METHODs')
    #ensemble.add_argument('--voting-strategy', default='soft', choices=('soft', 'hard'), help='Only for "Voting" and "Snapshot" METHODs')

    # HYPER PARAMETERS #
    model = parser.add_argument_group(title='Model Parameters')
    model.add_argument('--model', help='Model Class/Module Name or torch model checkpoint file', required=True)  # TODO checkopint file, also check loading from s3
    model.add_argument('--weights', default='DEFAULT', help='''Specify a model's weights. Either "DEFAULT", some specific identifier, or "None" for no-pretrained-weights''')
    model.add_argument('--seed', type=int, help='Set a specific seed for deterministic output')
    model.add_argument('--batch', dest='batch_size', metavar='SIZE', default=256, type=int, help='Number of images per batch. Defaults is 256')
    model.add_argument('--num-classes', type=int, help=argparse.SUPPRESS)
    model.add_argument('--freeze', metavar='LAYERS', help='Freezes a models leading feature layers. '
        'Positive int freezes the first N layers/features/blocks. A negative int like "-1" freezes all but the last feature/layer/block. '
        'A positive float like "0.8" freezes the leading 80%% of features/layers/blocks. fc or final classifier layers are never frozen.')

    model.add_argument('--loss-function', metavar='MODULE.CLASS', default='CrossEntropyLoss', help=argparse.SUPPRESS)
    model.add_argument('--loss-weights', default=False, help='If "normalize", rare class instances will be boosted. Else a filepath to a perclass list of loss weights. Default is None')
    model.add_argument('--loss-weights-tensor', help=argparse.SUPPRESS)
    model.add_argument('--loss-smoothing', nargs='?', default=0.0, const=0.1, type=float, help='Label Smoothing Regularization arg. Range is 0-1. Default is 0. Const is 0.1')

    model.add_argument('--epochs', metavar='MAX', default=100, type=int, help='Maximum number of training epochs. Default is 100')

    model.add_argument('--early-stopping-rounds', metavar='EPOCHS', default=10, type=int, help='Early Stopping for Boosting. Default is 10')
    parser.add_argument('--workers', dest='num_workers', metavar='N', type=int, help='Total number of dataloader worker threads. If set, overrides --workers-per-gpu')
    parser.add_argument('--workers_per_gpu', metavar='N', default=4, type=int, help='Number of data-loading threads per GPU. 4 per GPU is typical. Default is 4')
    parser.add_argument('--gpus', nargs='+', type=int, help=argparse.SUPPRESS) # CUDA_VISIBLE_DEVICES
    parser.add_argument('--outdir', default='./experiments/{EXPERIMENT}__{METHOD}__{MODEL}/{RUN}')
    parser.add_argument('--env', metavar='FILE', nargs='?', const=True, help='Environment Variables file. If set but not specified, attempts to find a parent .env file')

    return parser


def argparse_runtime_args(args):
    # Record GPUs
    if not args.gpus:
        args.gpus = [int(gpu) for gpu in os.environ.get('CUDA_VISIBLE_DEVICES','UNSET').split(',') if gpu!='' and gpu!='UNSET']
    if not args.num_workers:
        args.num_workers = len(args.gpus)*args.workers_per_gpu

    if not args.run:
        args.run = coolname.generate_slug(2)
    print(f'RUN: {args.run}')

    # Set Seed. If args.seed is 0 ie None, a random seed value is used and stored
    if args.seed is None:
        args.seed = random.randint(0,2**32-1)
    args.seed = torch.manual_seed(args.seed)

    # format Freeze to int or float
    if args.freeze:
        args.freeze = float(args.freeze) if '.' in args.freeze else int(args.freeze)

    args.model = check_model_name(args.model)
    args.outdir = args.outdir.format(EXPERIMENT=args.experiment,
            METHOD=args.ensemble, MODEL=args.model, RUN=args.run)
    os.makedirs(args.outdir, exist_ok=True)
    print(f'OUTDIR: {args.outdir}')


from typing import Union, Optional
from torch import Tensor
from torch.nn import CrossEntropyLoss, functional as F
from collections import namedtuple
class CleverCrossEntropyLoss(CrossEntropyLoss):
    INCEPTION_AUXLOSS_WEIGHT = 0.4
    GOOGLENET_AUXLOSS_WEIGHT = 0.3

    def forward(self, input: Union[Tensor,namedtuple], target: Tensor) -> Tensor:
        if isinstance(input, tuple) and hasattr(input, 'aux_logits'):
            loss = self.loss(input.logits, target)
            loss_aux = self.loss(input.aux_logits, target)
            batch_loss = loss + self.INCEPTION_AUXLOSS_WEIGHT * loss_aux
        elif isinstance(input, tuple) and hasattr(input, 'aux_logits2'):
            loss = self.loss(input.logits, target)
            loss_aux2 = self.loss(input.aux_logits2, target)
            loss_aux1 = self.loss(input.aux_logits1, target)
            batch_loss = loss + self.GOOGLENET_AUXLOSS_WEIGHT * loss_aux1 + self.GOOGLENET_AUXLOSS_WEIGHT * loss_aux2
        else:
            batch_loss = self.loss(input, target)
        return batch_loss

    def loss(self, input: Tensor, target: Tensor) -> Tensor:
        return F.cross_entropy(
            input,
            target,
            weight=self.weight,
            ignore_index=self.ignore_index,
            reduction=self.reduction,
            label_smoothing=self.label_smoothing,
        )

from collections import namedtuple
import warnings
def patch_iv3(model):
    InceptionOutputsPatch = namedtuple("InceptionOutputs", ["logits", "aux_logits", 'data', 'softmax', 'size'])
    InceptionOutputsPatch.__annotations__ = {"logits": Tensor, "aux_logits": Optional[Tensor]}
    def eager_outputs(self, x: Tensor, aux: Optional[Tensor]) -> InceptionOutputsPatch:
        if self.training and self.aux_logits:
            return InceptionOutputsPatch(x, aux, x, x.softmax, x.size)
        else:
            return x  # type: ignore[return-value]

    def forward(self, x: Tensor) -> InceptionOutputsPatch:
        x = self._transform_input(x)
        x, aux = self._forward(x)
        aux_defined = self.training and self.aux_logits
        if torch.jit.is_scripting():
            if not aux_defined:
                warnings.warn("Scripted Inception3 always returns Inception3 Tuple")
            return InceptionOutputsPatch(x, aux, x, x.softmax, x.size)
        else:
            return self.eager_outputs(x, aux)

    model.eager_outputs = eager_outputs.__get__(model, Inception3)
    model.forward = forward.__get__(model, Inception3)
    return model


def patch_goog(model):
    GoogLeNetOutputsPatch = namedtuple("GoogLeNetOutputs", ["logits", "aux_logits2", "aux_logits1", 'data', 'softmax', 'size'])
    GoogLeNetOutputsPatch.__annotations__ = {"logits": Tensor, "aux_logits2": Optional[Tensor], "aux_logits1": Optional[Tensor]}

    def eager_outputs(self, x: Tensor, aux2: Tensor, aux1: Optional[Tensor]) -> GoogLeNetOutputsPatch:
        if self.training and self.aux_logits:
            return GoogLeNetOutputsPatch(x, aux2, aux1 , x, x.softmax, x.size)
        else:
            return x  # type: ignore[return-value]

    def forward(self, x: Tensor) -> GoogLeNetOutputsPatch:
        x = self._transform_input(x)
        x, aux1, aux2 = self._forward(x)
        aux_defined = self.training and self.aux_logits
        if torch.jit.is_scripting():
            if not aux_defined:
                warnings.warn("Scripted GoogleNet always returns GoogleNetOutputs Tuple")
            return GoogLeNetOutputsPatch(x, aux2, aux1, x, x.softmax, x.size)
        else:
            return self.eager_outputs(x, aux2, aux1)

    model.eager_outputs = eager_outputs.__get__(model, GoogLeNet)
    model.forward = forward.__get__(model, GoogLeNet)
    return model


def patch_save(trainer: pl.Trainer, lightning_module, datamodule):
    import types
    from lightning.pytorch.trainer.trainer import TrainerFn, TrainerStatus, \
        _verify_loop_configurations, call, _log_hyperparams
    from lightning.pytorch.loops.evaluation_loop import _set_sampler_epoch
    from torchensemble.utils.io import save as f
    torchensemble_save_deepcopy = types.FunctionType(
        f.__code__, f.__globals__, f.__name__, f.__defaults__, f.__closure__)
    model = lightning_module
    model.trainer = trainer
    #model.metrics_to('cuda' if torch.cuda.is_available() else 'cpu')
    #model.trainer.fit()
    trainer.state.fn = TrainerFn.FITTING
    trainer.state.status = TrainerStatus.RUNNING
    trainer.training = True
    from copy import deepcopy
    trainer._data_connector.attach_data(model, datamodule=deepcopy(datamodule))
    trainer.fit_loop.min_epochs = 0
    trainer.fit_loop.max_epochs = -1
    trainer.strategy.connect(model)
    trainer._callback_connector._attach_model_callbacks()
    trainer._callback_connector._attach_model_logging_functions()
    _verify_loop_configurations(trainer)
    # SET UP THE TRAINER
    trainer.strategy.setup_environment()
    trainer._data_connector.prepare_data()
    call._call_setup_hook(trainer)
    call._call_configure_model(trainer)
    trainer._logger_connector.reset_results()
    trainer._logger_connector.reset_metrics()
    trainer.strategy.setup(trainer)
    #if self.state.fn == TrainerFn.FITTING:
    #    call._call_callback_hooks(self, "on_fit_start")
    #    call._call_lightning_module_hook(self, "on_fit_start")
    _log_hyperparams(trainer)
    trainer._checkpoint_connector.restore_training_state()
    trainer._checkpoint_connector.resume_end()
    trainer._signal_connector.register_signal_handlers()
    # RUN THE TRAINER
    #results = self._run_stage()
    #self.fit_loop.run()
    self = trainer.fit_loop
    self.setup_data()
    self.reset()
    self.on_run_start()
    ## self.on_advance_start() ##
    # update the epoch value for all samplers
    assert self._combined_loader is not None
    for i, dl in enumerate(self._combined_loader.flattened):
        _set_sampler_epoch(dl, self.epoch_progress.current.processed)
    self.epoch_progress.increment_ready()
    # call._call_callback_hooks(trainer, "on_train_epoch_start")
    # call._call_lightning_module_hook(trainer, "on_train_epoch_start")
    self.epoch_progress.increment_started()
    ## self.advance() ##
    combined_loader = self._combined_loader
    ### self.epoch_loop.run(self._data_fetcher)
    self.epoch_loop.reset()
    self.epoch_loop.on_run_start(self._data_fetcher)
    def run_one_lightning_validation_epoch():
        #self.epoch_loop.advance(self._data_fetcher)
        self.epoch_loop.on_advance_end(self._data_fetcher)  # VALIDATION HAPPENS HERE!!
        trainer.checkpoint_callback.on_validation_end(trainer, model)
        self._restarting = False
        ## self.on_advance_end() ##
        trainer._logger_connector.epoch_end_reached()
        self.epoch_progress.increment_processed()
        call._call_callback_hooks(trainer, "on_train_epoch_end", monitoring_callbacks=False)
        call._call_lightning_module_hook(trainer, "on_train_epoch_end")
        call._call_callback_hooks(trainer, "on_train_epoch_end", monitoring_callbacks=True)
        trainer._logger_connector.on_epoch_end()
        self.epoch_loop._batches_that_stepped -= 1
        trainer._logger_connector.update_train_epoch_metrics()
        self.epoch_loop._batches_that_stepped += 1
        self.epoch_progress.increment_completed()
        self._restarting = False
    def save_bestepoch_ckpt(model, save_dir, logger):
        # {Ensemble_Model_Name}_{Base_Estimator_Name}_{n_estimators}
        filename = "{}_{}_{}_ckpt.pth".format(
            type(model).__name__,
            model.base_estimator_.__class__.__name__,
            model.n_estimators,
        )
        fullpath = os.path.join(save_dir,filename)
        if lightning_module.best_epoch == lightning_module.current_epoch-1:
            if isinstance(lightning_module.logger,AimLogger):
                if 'AIM_ARTIFACTS_URI' in os.environ and os.environ['AIM_ARTIFACTS_URI']:
                    logger.info(f'Saving model to {lightning_module.logger.experiment.artifacts_uri}/{filename}')
                    lightning_module.logger.experiment.log_artifact(fullpath, filename)
    def new_save(model, save_dir, logger):
        torchensemble_save_deepcopy(model, save_dir, logger)
        run_one_lightning_validation_epoch()
        save_bestepoch_ckpt(model, save_dir, logger)
        model.to('cuda' if torch.cuda.is_available() else 'cpu')
        return
    return new_save

def patch_boosting_earlystopping(save_dir='/tmp/torchensemble_boosting'):
    # must be called AFTER patch_save()
    import types
    from torchensemble.utils import io
    f = GradientBoostingClassifier._handle_early_stopping
    _handle_early_stopping__deepcopy = types.FunctionType(
        f.__code__, f.__globals__, f.__name__, f.__defaults__, f.__closure__)
    def new_earlystopping(self, test_loader, est_idx):
        flag, acc = _handle_early_stopping__deepcopy(self, test_loader, est_idx)
        io.save(self, save_dir, self.logger)
        return flag, acc
    return new_earlystopping


def main(args):
    torch.set_float32_matmul_precision('medium')

    if args.env:
        load_dotenv(override=True) if args.env is True else load_dotenv(args.env, override=True)
    os.environ['CUDA_VISIBLE_DEVICES'] = ','.join(map(str,args.gpus))

    import torchensemble
    try:
        logger = torchensemble.utils.logging.set_logger(log_file=args.run,
            log_console_level="info", log_file_level='info', use_tb_logger=True)
    except ImportError:
        logger = torchensemble.utils.logging.set_logger(log_file=args.run,
            log_console_level="info", log_file_level='info', use_tb_logger=False)
        tb_logdir = logger.root.handlers[0].baseFilename.replace('.log','_tb_logger')
        logger.info(f'tensorboard not installed, removing tb_logdir: {tb_logdir}')
        os.rmdir(tb_logdir)

    # Setup Model & Data Module

    lightning_module, datamodule = setup_model_and_datamodule(args)
    basemodel_args = {k: getattr(args, k) for k in 'model batch_size num_classes freeze weights'.split()}
    logger.info(f'base_model: {basemodel_args}')
    base_model = lightning_module.model
    if isinstance(base_model, Inception3):
        base_model = patch_iv3(base_model)
        #base_model.aux_logits = False
    if isinstance(base_model, GoogLeNet):
        base_model = patch_goog(base_model)
        #base_model.aux_logits = False
    datamodule.setup('fit', without_source=True)

    ensemble_args = dict(n_estimators=args.num_ensembles, cuda=torch.cuda.is_available())
    fit_args = dict()
    match args.ensemble:
        case 'Voting':
            EnsembleMethod = VotingClassifier
            ensemble_args['voting_strategy'] = args.voting_strategy
        case 'Snapshot':
            EnsembleMethod = SnapshotEnsembleClassifier
            ensemble_args['voting_strategy'] = args.voting_strategy
            fit_args['lr_clip'] = None
        case 'Adversarial':
            EnsembleMethod = AdversarialTrainingClassifier
            fit_args['epsilon'] = 0.5
        case 'Boosting':
            EnsembleMethod = GradientBoostingClassifier
            base_model.aux_logits = False
            fit_args['use_reduction_sum'] = True
            fit_args['early_stopping_rounds'] = args.early_stopping_rounds
        case 'FastGeometric':
            EnsembleMethod = FastGeometricClassifier
            fit_args['cycle'] = 4
            fit_args['lr_1'] = 5e-2
            fit_args['lr_2'] = 1e-4
        case 'Fusion':
            EnsembleMethod = FusionClassifier
            base_model.aux_logits = False
        case 'Bagging':
            EnsembleMethod = BaggingClassifier
        case _:
            raise ValueError

    logger.info(f'ensemble_args: {ensemble_args}')
    ensemble = EnsembleMethod(estimator=base_model, **ensemble_args)

    # Loss Function
    if args.loss_function == 'CrossEntropyLoss':
        Criterion = torch.nn.CrossEntropyLoss
        if isinstance(base_model,(Inception3,GoogLeNet)):
            Criterion = CleverCrossEntropyLoss
    else:
        raise NotImplemented(f'--loss-function {args.loss_function}')
    criterion_args = dict(weight=args.loss_weights_tensor, label_smoothing=args.loss_smoothing)
    logger.info(f'criterion_args: {criterion_args}')
    criterion = Criterion(**criterion_args)
    ensemble.set_criterion(criterion)

    # Gradient Descent Optimizer
    optimizer_args = dict(optimizer_name="Adam", lr=0.001, weight_decay=0)
    logger.info(f'optimizer_args: {optimizer_args}')
    ensemble.set_optimizer(**optimizer_args)

    # Set the learning rate scheduler
    #ensemble.set_scheduler("CosineAnnealingLR", T_max=...)

    ## LIGHTNING TRAINER SAVE PATCH ##
    logger_kwargs = dict(experiment=args.experiment, run_name=args.run,
                         context_postfixes=dict(
                             averaging={'macro': '_macro', 'micro': '_micro', 'weighted': '_weighted',
                                        'none': '_perclass'},  # f1, precision, recall
                             normalized={'no': '_summed', 'yes': '_normalized'}))

    if 'AIM_REPO' in os.environ and os.environ['AIM_REPO']:
        aim_logger = AimLoggerWithContext(repo=os.environ['AIM_REPO'], **logger_kwargs)
        if 'AIM_ARTIFACTS_URI' in os.environ and os.environ['AIM_ARTIFACTS_URI']:
            aim_logger.experiment.set_artifacts_uri(os.environ['AIM_ARTIFACTS_URI'])

        if args.note: aim_logger.experiment.props.description = args.note

        if 'AIM_ARTIFACTS_URI' in os.environ and os.environ['AIM_ARTIFACTS_URI']:
            if os.path.isfile(args.classlist):
                aim_logger.experiment.log_artifact(args.classlist, name=os.path.basename(args.classlist))
            if os.path.isfile(args.vallist):
                aim_logger.experiment.log_artifact(args.vallist, name=os.path.basename(args.vallist))
            if os.path.isfile(args.trainlist):
                aim_logger.experiment.log_artifact(args.vallist, name=os.path.basename(args.trainlist))
    else:
        aim_logger = None

    callbacks = [
        BarPlotMetricAim('f1_perclass', order_by='f1_perclass', best_only=False),
        PlotConfusionMetricAim(order_by='classes', normalize=True, best_only=False),
        PlotConfusionMetricAim(order_by='f1_perclass', normalize=True, best_only=False),
        PlotPerclassDropdownAim(best_only=False),
        ]


    trainer = pl.Trainer(num_sanity_val_steps=0,
                         accelerator='auto', devices='auto', num_nodes=1,
                         logger=aim_logger,
                         log_every_n_steps=-1,
                         callbacks=callbacks,
    )

    import torchensemble.utils.io
    lightning_module_with_ensemble = MulticlassClassifier(args, model=ensemble)
    torchensemble.utils.io.save = patch_save(trainer, lightning_module_with_ensemble, datamodule)
    if args.ensemble == 'Boosting':
        ensemble._handle_early_stopping = patch_boosting_earlystopping().__get__(ensemble, GradientBoostingClassifier)

    # FIT THE MODEL
    fit_args['epochs'] = args.epochs
    fit_args['save_dir'] = args.outdir
    #fit_args['log_interval'] = 100
    logger.info(f'fit_args: {fit_args}')
    ensemble.fit(train_loader = datamodule.train_dataloader(),
                 **fit_args)


if __name__ == '__main__':
    parser = argparse_init()
    args = parser.parse_args()
    argparse_runtime_args(args)
    main(args)

