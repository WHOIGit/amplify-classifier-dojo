import os
import argparse
import random

import coolname
import torchvision
from aim.pytorch_lightning import AimLogger
from dotenv import load_dotenv

import torch
import lightning.pytorch as pl
from lightly.transforms import SimCLRTransform
from lightning.pytorch.callbacks import ModelCheckpoint
from lightning.pytorch.tuner import Tuner
from torch.utils.data import DataLoader
from torch.utils.data.datapipes.iter import Shuffler

# set import paths to project root
if __name__ == '__main__':
    import sys, pathlib
    PROJECT_ROOT = pathlib.Path(__file__).parent.parent.parent.absolute()
    if sys.path[0] != str(PROJECT_ROOT): sys.path.insert(0, str(PROJECT_ROOT))

from src.multiclass.models import check_model_name, get_model_base_transforms, get_namebrand_model, get_model_resize
from src.selfsupervised.datasets import IfcbBinsDataset
from src.selfsupervised.models import SimCLR
from src.multiclass.callbacks import LogNormalizedLoss
from src.train import setup_aimlogger
from src.multiclass.datasets import ImageDatasetWithSource, parse_classlist, parse_listfile_with_targets
from src.tools.dataset_lists_from_folder import balanced_split


def argparse_init(parser=None):
    if parser is None:
        parser = argparse.ArgumentParser(description='Train an image classifier!')

    # DATASET #
    dataset = parser.add_argument_group(title='Dataset', description=None)
    dataset.add_argument('--trainlist', required=True, help='A text file, one ifcb bin-directory per line.')
    dataset.add_argument('--vallist', required=True, help='Like trainlist, but for validation metrics and early-stopping/overfit-prevention')
    dataset.add_argument('--classlist', required=True, help='A text file, each line is a class label (the label order is significant), or a json dict')

    # TRACKING #
    aimstack = parser.add_argument_group(title='AimLogger', description=None)
    aimstack.add_argument('--run', help='The name of this run. A run name is automatically generated by default')
    aimstack.add_argument('--experiment', help='The broader category/grouping this RUN belongs to')
    aimstack.add_argument('--note', help='Add any kind of note or description to the trained model. Make sure to use quotes "around your message."')
    aimstack.add_argument('--repo', help='Aim repo path. Also see: Aim environment variables.')
    aimstack.add_argument('--artifacts-location', help='Aim Artifacts location. Also see: Aim environment variables.')
    #aimstack.add_argument('--plot', nargs='+', action='append', ...)
    #aimstack.add_argument('--callback', nargs='+', action='append', ...)
    #aimstack.add_argument('--metric', nargs='+', action='append', ...)

    # HYPER PARAMETERS #
    model = parser.add_argument_group(title='Model Parameters')
    model.add_argument('--model-name', help='Model Class/Module Name or torch model checkpoint file', required=True)  # TODO checkopint file, also check loading from s3
    model.add_argument('--weights', default='DEFAULT', help='''Specify a model's weights. Either "DEFAULT", some specific identifier, or "None" for no-pretrained-weights''')
    model.add_argument('--seed', type=int, help='Set a specific seed for deterministic output')
    model.add_argument('--batch', dest='batch_size', metavar='SIZE', default=256, type=int, help='Number of images per batch. Defaults is 256')

    epochs = parser.add_argument_group(title='Epoch Parameters')
    epochs.add_argument('--epoch-max', metavar='MAX', default=100, type=int, help='Maximum number of training epochs. Default is 100')
    epochs.add_argument('--epoch-min', metavar='MIN', default=10, type=int, help='Minimum number of training epochs. Default is 10')
    epochs.add_argument('--epoch-stop', metavar='STOP', default=10, type=int, help='Early Stopping: Number of epochs following a best-epoch after-which to stop training. Set STOP=0 to disable. Default is 10')

    # UTILITIES #
    parser.add_argument('--checkpoints-path', default='/tmp/classifier_checkpoints')
    parser.add_argument('--autobatch', nargs='?', default=False, const='power', choices=['power','binsearch'], help='Auto-Tunes batch_size prior to training/inference.')
    parser.add_argument('--autobatch-max', type=int, help='Disallow autobatch for setting ')
    parser.add_argument('--workers', dest='num_workers', metavar='N', type=int, help='Total number of dataloader worker threads. If set, overrides --workers-per-gpu')
    parser.add_argument('--workers_per_gpu', metavar='N', default=4, type=int, help='Number of data-loading threads per GPU. 4 per GPU is typical. Default is 4')
    parser.add_argument('--fast-dev-run', default=False, action='store_true')
    parser.add_argument('--env', metavar='FILE', nargs='?', const=True, help='Environment Variables file. If set but not specified, attempts to find a parent .env file')
    parser.add_argument('--gpus', nargs='+', type=int, help=argparse.SUPPRESS) # CUDA_VISIBLE_DEVICES

    return parser


def argparse_runtime_args(args):
    # Record GPUs
    if not args.gpus:
        args.gpus = [int(gpu) for gpu in os.environ.get('CUDA_VISIBLE_DEVICES','UNSET').split(',') if gpu not in ['','UNSET']]

    if args.env:
        load_dotenv(override=True) if args.env is True else load_dotenv(args.env, override=True)
    os.environ['CUDA_VISIBLE_DEVICES'] = ','.join(map(str,args.gpus))  # reset if not included in .env

    if not args.num_workers:
        args.num_workers = len(args.gpus)*args.workers_per_gpu

    # Record Version
    try:
        with open('VERSION') as f:
            args.version = f.read().strip()
    except FileNotFoundError:
        args.version = None

    # Set Seed. If args.seed is 0 ie None, a random seed value is used and stored
    if args.seed is None:
        args.seed = random.randint(1,2**32-1)
    args.seed = pl.seed_everything(args.seed)

    if not args.run:
        args.run = coolname.generate_slug(2)
        print(f'RUN: {args.run}')

    if args.artifacts_location and os.path.isdir(args.artifacts_location):
        args.artifacts_location = f'file://{os.path.abspath(args.artifacts_location)}'
    if 'AIM_ARTIFACTS_URI' in os.environ and os.environ['AIM_ARTIFACTS_URI']:
        if os.path.isdir(os.environ['AIM_ARTIFACTS_URI']):
            os.environ['AIM_ARTIFACTS_URI'] = f'file://{os.path.abspath(os.environ["AIM_ARTIFACTS_URI"])}'

    # Trainlist is a list of dirs, special handling
    if os.path.isfile(args.trainlist):
        with open(args.trainlist) as f:
            args.trainlist = f.read().splitlines()
        assert all([os.path.isdir(d) for d in args.trainlist])
    elif os.path.isdir(args.trainlist):
        args.trainlist = [args.trainlist]
    else:
        raise ValueError


def setup_model_and_datamodule(args):

    # TODO make this a lightning datamodule

    # Training Dataloader
    assert args.model_name=='resnet18'
    args.model = check_model_name(args.model_name)
    resize = get_model_resize(args.model_name)
    transform = SimCLRTransform(input_size=resize, vf_prob=0.5, hf_prob=0.5, cj_prob=0.5, cj_strength=0.5)
    dataset = IfcbBinsDataset(args.trainlist, transform=transform)
    dataset.calculate_len()
    shuff = Shuffler(dataset, buffer_size=1000)
    dataloader = DataLoader(shuff, batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers, drop_last=True)

    # Validation Dataloader
    if args.vallist:
        assert args.classlist
        val_transforms = get_model_base_transforms(args.model_name)
        validation_transform = torchvision.transforms.Compose(val_transforms)
        classes = parse_classlist(args.classlist)
        val_data_full, val_ds_errors = parse_listfile_with_targets(args.vallist, len(classes))
        if val_ds_errors:
            raise RuntimeError(f'BAD SAMPLES: {len(val_ds_errors)}')
        val_images_perclass = ImageDatasetWithSource(sources_targets=val_data_full, classes=classes).images_perclass
        knn_data,val_data = balanced_split(val_images_perclass, ratio=0.5)
        knn_dataset = ImageDatasetWithSource(knn_data, classes, validation_transform)
        val_dataset = ImageDatasetWithSource(val_data, classes, validation_transform)
        knn_dataloader = DataLoader(knn_dataset, batch_size=args.batch_size, num_workers=args.num_workers)
        val_dataloader = DataLoader(val_dataset, batch_size=args.batch_size, num_workers=args.num_workers)

    else:
        knn_dataloader = []
        val_dataloader = []


    # todo make a backbone creator
    #get_namebrand_model
    #backbone_model, output_feature_num = get_namebrand_model_backbone(model_name, weights)
    # using a resnet backbone
    resnet = torchvision.models.resnet18()
    backbone = torch.nn.Sequential(*list(resnet.children())[:-1])
    backbone_outfeatures = resnet.fc.in_features

    # TODO other architectures, like VICReg
    model = SimCLR(backbone, backbone_outfeatures, 128, knn_dataloader)  # TODO what is mystery number 126
    return model, dataloader, val_dataloader



def main(args):
    torch.set_float32_matmul_precision('medium')

    ## Setup Model & Data Module ##
    model, dataloader, val_dataloader = setup_model_and_datamodule(args)

    ## Setup Epoch Logger ##
    # val_/train_ already handled by default
    logger = setup_aimlogger(args)

    ## Setup Callbacks ##
    callbacks=[]

    validation_results_callbacks = [
        LogNormalizedLoss(),
    ]
    callbacks.extend(validation_results_callbacks)

    # Checkpointing
    # https://lightning.ai/docs/pytorch/stable/api/lightning.pytorch.callbacks.ModelCheckpoint.html
    # https://lightning.ai/docs/pytorch/stable/common/checkpointing_advanced.html
    hashid = logger.experiment.hash if isinstance(logger,AimLogger) else logger[0].experiment.hash
    chkpt_path = os.path.join(args.checkpoints_path,hashid)
    ckpt_callback = ModelCheckpoint(
        dirpath=chkpt_path, filename='best.ckpt',
        monitor='val_loss', mode='min')
    callbacks.append(ckpt_callback)

    ## Setup Trainer  ##
    trainer = pl.Trainer(num_sanity_val_steps=0,
                         deterministic=True,
                         accelerator='auto', devices='auto', num_nodes=1,
                         max_epochs=args.epoch_max, min_epochs=args.epoch_min,
                         precision='32',
                         logger=logger,
                         log_every_n_steps=-1,
                         callbacks=callbacks,
                         fast_dev_run=args.fast_dev_run,
                        )

    # auto-tune batch-size
    if args.autobatch:
        tuner = Tuner(trainer)
        found_batch_size = tuner.scale_batch_size(model, train_dataloaders=dataloader,
            mode=args.autobatch, method='fit', max_trials=10, init_val=args.batch_size)
        args.batch_size_init, args.batch_size = args.batch_size, min([found_batch_size, args.autobatch_max or float('inf')])

    trainer.fit(model, train_dataloaders=dataloader, val_dataloaders=val_dataloader)


if __name__ == '__main__':
    parser = argparse_init()
    args = parser.parse_args()
    argparse_runtime_args(args)
    main(args)